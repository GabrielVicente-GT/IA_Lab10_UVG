{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidad del valle de Guatemala</br>\n",
    "Facultad de Ingeniería</br>\n",
    "Departamento de ciencias de la Computación</br>\n",
    "Inteligencia Artificial\n",
    "\n",
    "# Laboratorio 10: Clasificador de Imágenes (Perros vs Gatos) </br>\n",
    "Deberá construir un modelo basado en redes neuronales que le permita clasificar perros y gatos basado en un input\n",
    "de imágen. Para esto, deberá usar técnicas basadas en Deep Learning relacionadas con el manejo de imágenes\n",
    "como las redes convolucionales. \n",
    "\n",
    "Grupo # 4</br>\n",
    "Gabriel Vicente 2049"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1 - Lectura del Dataset\n",
    "\n",
    "En esta ocasión no recibirá un documento único como entrada de datos, por el contrario deberá recibir un conjunto\n",
    "de imágenes que representan perros y gatos. Estos datos los puede descargar de este dataset de Kaggle. Deberá\n",
    "leer estas imágenes para crear un dataset en memoria que haga referencia a la imagen con sus características y a\n",
    "la categoría a la que pertenece. Recuerde que debe dividir su dataset según el uso y como se mencionó\n",
    "anteriormente. Además, considere que la cantidad de imágenes de perros y gatos puede estar desigual por lo que\n",
    "deberá aplicar las técnicas aprendidas durante el curso para lidiar con este problema Son libres de usar todas las\n",
    "imágenes del dataset dado o bien una cantidad definida por ustedes mismos siempre y cuando se argumente la\n",
    "razón de forma debida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports para que el proyecto funcione\n",
    "# En este caso se decidio utilizar tenserflow\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del dataset de PetImages se cargan 3000 de cada tipo (Gato y Perro) para que el modelo se entrene. A partir de esto hacemos un reacomodamiento, resize y finalmente lo cargamos. De ser una imagen corrupta se descarta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directorio de datos\n",
    "DATADIR = \"PetImages\"\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "\n",
    "# Tamaño de las imágenes\n",
    "IMG_SIZE = 50\n",
    "\n",
    "# Cargar imágenes\n",
    "training_data = []\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    class_num = CATEGORIES.index(category)\n",
    "    for img in os.listdir(path)[:3000]:  # Tomar solo 3000 imágenes\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "            training_data.append([new_array, class_num])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2 - Construcción del Modelo\n",
    "\n",
    "Deberá crear un modelo de Deep Learning orientado a imágenes, como una red que usa capas convolucionales,\n",
    "para poder resolver este laboratorio. Recuerde que deberá definir la arquitectura de su red, aplicando las diferentes\n",
    "técnicas vistas en clase (dropouts, funciones de activación, padding, stride, etc). Podrá usar la librería que más le\n",
    "parezca para completar el laboratorio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 10s 59ms/step - loss: 0.6899 - accuracy: 0.5171 - val_loss: 0.6746 - val_accuracy: 0.5539\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 8s 56ms/step - loss: 0.6572 - accuracy: 0.6031 - val_loss: 0.6211 - val_accuracy: 0.6658\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 8s 51ms/step - loss: 0.6261 - accuracy: 0.6509 - val_loss: 0.6016 - val_accuracy: 0.6767\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.5807 - accuracy: 0.7003 - val_loss: 0.5830 - val_accuracy: 0.7009\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 9s 58ms/step - loss: 0.5404 - accuracy: 0.7333 - val_loss: 0.5626 - val_accuracy: 0.7310\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.4982 - accuracy: 0.7552 - val_loss: 0.5702 - val_accuracy: 0.7101\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 9s 63ms/step - loss: 0.4541 - accuracy: 0.7916 - val_loss: 0.5104 - val_accuracy: 0.7527\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 9s 60ms/step - loss: 0.4134 - accuracy: 0.8077 - val_loss: 0.4979 - val_accuracy: 0.7586\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 0.3581 - accuracy: 0.8416 - val_loss: 0.5236 - val_accuracy: 0.7661\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 9s 58ms/step - loss: 0.3127 - accuracy: 0.8610 - val_loss: 0.5765 - val_accuracy: 0.7561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x299d2314a30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Seteando los datos a un ancho alto y almacenandolos\n",
    "data = np.array([i[0] for i in training_data]) / 255.0\n",
    "labels = np.array([i[1] for i in training_data])\n",
    "data = np.reshape(data, (data.shape[0], IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "print(\"Metricas de desempeño\")\n",
    "\n",
    "# 80 training 20 testing\n",
    "(train_data, test_data, train_labels, test_labels) = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construccion del modelo\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Ejecutar el modelo\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entrenando\n",
    "model.fit(train_data, train_labels, epochs=10, validation_data=(test_data, test_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3 - Desempeño del Modelo\n",
    "\n",
    "Al finalizar el entrenamiento de su modelo, permita que se ingresen nuevas imágenes y permita que el modelo la\n",
    "clasifique. Además recuerde medir el desempeño de su modelo tanto en entrenamiento como en testing. Para ello,\n",
    "deberá mostrar las métricas de desempeño de su modelo para las fases dichas, además de la evolución de las\n",
    "métricas durante las diferentes épocas, cuidando siempre no hacer overfitting sobre el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "La imagen es un gato\n"
     ]
    }
   ],
   "source": [
    "# De la prueba 1 a la 3 son gatos\n",
    "# De la prueba 4 a la 7 son perros\n",
    "img_path = './TestImages/Prueba1.jpg'\n",
    "\n",
    "try:\n",
    "    # Cargando la imagen\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = np.array(img) / 255.0\n",
    "    img = np.reshape(img, (1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "    # Resultado de probabilidad\n",
    "    prediction = model.predict(img)\n",
    "\n",
    "    # Eleccion final\n",
    "    if prediction[0] < 0.5:\n",
    "        print(\"La imagen es un perro\")\n",
    "    else:\n",
    "        print(\"La imagen es un gato\")\n",
    "except:\n",
    "    print(\"Ruta no valida\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
